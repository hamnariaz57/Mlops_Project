# ğŸš€ MLOps Phase 1: Real-Time Predictive System (RPS)
## Exchange Rate Prediction Pipeline

[![MLOps](https://img.shields.io/badge/MLOps-Phase%201-blue)](https://github.com/hamnariaz57/Mlops_Project)
[![Airflow](https://img.shields.io/badge/Apache-Airflow-017CEE?logo=apache-airflow)](https://airflow.apache.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)

---

## ğŸ“‹ **Project Overview**

This project implements a **complete MLOps Phase 1 pipeline** for a Real-Time Exchange Rate Predictive System. It demonstrates production-grade practices including:

- âœ… **Automated Data Ingestion** from live APIs
- âœ… **Mandatory Data Quality Gates** (fail-fast approach)
- âœ… **Feature Engineering** for time-series data
- âœ… **Data Versioning** with DVC
- âœ… **Experiment Tracking** with MLflow (DagHub)
- âœ… **Orchestration** with Apache Airflow

---

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Apache Airflow DAG (Daily)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: EXTRACTION                                              â”‚
â”‚  â”œâ”€ Fetch data from Exchange Rate API                           â”‚
â”‚  â”œâ”€ Save raw data with timestamp                                â”‚
â”‚  â””â”€ Store in: data/raw/exchange_rates_raw_YYYYMMDD_HHMMSS.csv  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: QUALITY CHECK (MANDATORY GATE) âš ï¸                      â”‚
â”‚  â”œâ”€ Check null values < 1%                                       â”‚
â”‚  â”œâ”€ Validate schema                                              â”‚
â”‚  â”œâ”€ Verify minimum currency count                               â”‚
â”‚  â””â”€ FAIL pipeline if checks fail                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: TRANSFORMATION & FEATURE ENGINEERING                    â”‚
â”‚  â”œâ”€ Time-based features (day, month, quarter, hour)             â”‚
â”‚  â”œâ”€ Lag features (1-day, 7-day)                                 â”‚
â”‚  â”œâ”€ Rolling means (7-day, 30-day)                               â”‚
â”‚  â”œâ”€ Volatility measures (rolling std)                           â”‚
â”‚  â”œâ”€ Percentage changes (1-day, 7-day)                           â”‚
â”‚  â””â”€ Save to: data/processed/exchange_rates.csv                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: PANDAS PROFILING REPORT                                â”‚
â”‚  â”œâ”€ Generate comprehensive data quality report                  â”‚
â”‚  â”œâ”€ Save as HTML: reports/data_profile_TIMESTAMP.html          â”‚
â”‚  â””â”€ Log to MLflow (DagHub) as artifact                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: DATA VERSIONING (DVC)                                  â”‚
â”‚  â”œâ”€ dvc add data/processed/exchange_rates.csv                   â”‚
â”‚  â”œâ”€ dvc push (to DagHub S3 remote storage)                      â”‚
â”‚  â”œâ”€ git commit .dvc files                                        â”‚
â”‚  â””â”€ Complete data lineage tracking                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ **Project Structure**

```
Mlops_Project/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ exchange_rate_dag.py          # Complete Airflow DAG (Phase 1)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Raw API responses (timestamped)
â”‚   â”‚   â””â”€â”€ exchange_rates_raw_*.csv
â”‚   â””â”€â”€ processed/                     # Processed & engineered features
â”‚       â”œâ”€â”€ exchange_rates.csv         # Main dataset (DVC tracked)
â”‚       â””â”€â”€ exchange_rates.csv.dvc     # DVC metadata
â”‚
â”œâ”€â”€ reports/                           # Data quality reports
â”‚   â””â”€â”€ data_profile_*.html
â”‚
â”œâ”€â”€ docker-compose.yaml                # Airflow + PostgreSQL + MLflow
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env.example                       # Environment variables template
â”œâ”€â”€ .dvc/                              # DVC configuration
â”‚   â””â”€â”€ config                         # Remote storage config (DagHub)
â”‚
â”œâ”€â”€ README.md                          # This file
â””â”€â”€ PHASE1_IMPLEMENTATION_GUIDE.md     # Detailed setup guide
```

---

## ğŸ¯ **Phase 1 Requirements Implementation**

| Requirement | Status | Implementation |
|-------------|--------|----------------|
| **1.1: API Data Extraction** | âœ… | `extract_exchange_rate_data()` - Fetches from exchangerate-api.com |
| **1.2: Timestamp & Save Raw** | âœ… | Saves with `YYYYMMDD_HHMMSS` format |
| **2.1: Data Quality Gate** | âœ… | `data_quality_check()` - Fails DAG if thresholds breached |
| **2.2: Transformation** | âœ… | `transform_and_engineer_features()` - Lag, rolling, time features |
| **2.3: Pandas Profiling** | âœ… | `generate_profiling_report()` - HTML report + MLflow artifact |
| **3.1: DVC Versioning** | âœ… | `version_data_with_dvc()` - Automated versioning |
| **3.2: Remote Storage** | âœ… | DagHub S3 bucket configured |
| **Airflow Orchestration** | âœ… | Daily schedule with proper task dependencies |

---

## ğŸš€ **Quick Start Guide**

### **Prerequisites**

- Docker & Docker Compose installed
- Python 3.9+ (for local development)
- Git installed
- DagHub account (for MLflow & DVC remote)

### **Step 1: Clone & Setup**

```bash
# Clone repository
git clone https://github.com/hamnariaz57/Mlops_Project.git
cd Mlops_Project

# Create environment file
cp .env.example .env
# Edit .env and add your DAGSHUB_TOKEN
```

### **Step 2: Install Python Dependencies (Optional - for local testing)**

```bash
pip install -r requirements.txt
```

### **Step 3: Configure DVC Remote (Already configured)**

```bash
# Verify DVC remote
dvc remote list
# Output: storage  s3://hamnariaz57@dagshub.com/repo-buckets/s3/hamnariaz57
```

### **Step 4: Start Airflow**

```bash
# Start all services (Airflow + PostgreSQL + MLflow)
docker-compose up -d

# Wait for services to be healthy (~2 minutes)
docker-compose ps
```

### **Step 5: Access Airflow UI**

1. Open browser: **http://localhost:8080**
2. Login:
   - Username: `admin`
   - Password: `admin`
3. Enable the DAG: `exchange_rate_mlops_pipeline_phase1`
4. Trigger manually or wait for daily schedule

### **Step 6: Access MLflow UI**

1. Open browser: **http://localhost:5000**
2. View experiment runs, metrics, and artifacts

---

## ğŸ“Š **What the Pipeline Does**

### **Data Extraction**
```python
# Fetches from: https://api.exchangerate-api.com/v4/latest/USD
# Returns: ~160 currency exchange rates
# Saved as: data/raw/exchange_rates_raw_20251130_143025.csv
```

### **Quality Checks**
- âŒ **Fails if** > 1% null values
- âŒ **Fails if** < 10 currencies returned
- âŒ **Fails if** schema invalid
- âŒ **Fails if** non-numeric currency values

### **Feature Engineering**

| Feature Type | Examples |
|--------------|----------|
| **Time Features** | `day_of_week`, `month`, `quarter`, `hour` |
| **Lag Features** | `EUR_lag1`, `EUR_lag7` |
| **Rolling Means** | `EUR_rolling_mean_7`, `EUR_rolling_mean_30` |
| **Volatility** | `EUR_rolling_std_7`, `EUR_rolling_std_30` |
| **Rate of Change** | `EUR_pct_change_1d`, `EUR_pct_change_7d` |

### **Outputs**

1. **Processed Dataset**: `data/processed/exchange_rates.csv` (DVC tracked)
2. **Profiling Report**: `reports/data_profile_TIMESTAMP.html`
3. **MLflow Run**: Logged to DagHub with metrics & artifacts
4. **DVC Metadata**: `.dvc` files committed to Git

---

## ğŸ”§ **Configuration**

### **Airflow DAG Configuration**

```python
# In: dags/exchange_rate_dag.py

# Schedule
schedule_interval="@daily"  # Runs every day at midnight

# Data Quality Thresholds
NULL_THRESHOLD = 0.01  # 1% max null values
MIN_REQUIRED_CURRENCIES = 10

# API
API_URL = "https://api.exchangerate-api.com/v4/latest/USD"
```

### **Environment Variables**

```bash
# .env file

DAGSHUB_USERNAME=hamnariaz57
DAGSHUB_TOKEN=your_token_here
MLFLOW_TRACKING_URI=https://dagshub.com/hamnariaz57/Mlops_Project.mlflow
```

---

## ğŸ“ˆ **Monitoring & Logs**

### **Airflow Logs**
```bash
# View scheduler logs
docker-compose logs -f airflow-scheduler

# View webserver logs
docker-compose logs -f airflow-webserver
```

### **Task Logs**
- Access via Airflow UI â†’ DAG â†’ Task â†’ Logs
- Detailed output for each task (extraction, quality check, etc.)

### **MLflow Tracking**
- View runs at: **http://localhost:5000**
- Or on DagHub: **https://dagshub.com/hamnariaz57/Mlops_Project**

---

## ğŸ› **Troubleshooting**

### **Issue: Airflow containers not starting**
```bash
# Check logs
docker-compose logs postgres
docker-compose logs airflow-init

# Reset and restart
docker-compose down -v
docker-compose up -d
```

### **Issue: DVC push fails**
```bash
# Verify DagHub credentials
dvc remote list
dvc remote modify storage --local auth basic
dvc remote modify storage --local user hamnariaz57
dvc remote modify storage --local password YOUR_TOKEN

# Test connection
dvc push -r storage
```

### **Issue: MLflow not logging**
```bash
# Check MLflow service
docker-compose ps mlflow

# Verify environment variables in docker-compose
echo $DAGSHUB_TOKEN
```

---

## ğŸ“ **Next Steps (Phase 2)**

Phase 1 establishes the **data pipeline**. Next phases will include:

- âœ… **Phase 2**: Model training & hyperparameter tuning
- âœ… **Phase 3**: Model serving (REST API)
- âœ… **Phase 4**: Concept drift detection & retraining
- âœ… **Phase 5**: Monitoring dashboard

---

## ğŸ¤ **Contributing**

This is an academic project. For questions or improvements:

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“œ **License**

This project is for educational purposes as part of an MLOps case study.

---

## ğŸ‘¤ **Author**

**Hamna Riaz**
- GitHub: [@hamnariaz57](https://github.com/hamnariaz57)
- DagHub: [hamnariaz57](https://dagshub.com/hamnariaz57)

---

## ğŸ™ **Acknowledgments**

- **Exchange Rate API**: [exchangerate-api.com](https://exchangerate-api.com)
- **Apache Airflow**: Workflow orchestration
- **MLflow**: Experiment tracking
- **DVC**: Data version control
- **DagHub**: Remote storage & MLflow hosting

---

## ğŸ“ **Support**

If you encounter issues:

1. Check Airflow logs: `docker-compose logs -f`
2. Verify environment variables in `.env`
3. Ensure DagHub token is valid
4. Review task logs in Airflow UI

---

**Project Deadline**: November 30, 2025  
**Status**: âœ… Phase 1 Complete

---

